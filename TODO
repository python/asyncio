# -*- Mode: text -*-
   
TO DO SMALLER TASKS

- Make Task more like Future; getting result() should re-raise exception.


TO DO LARGER TASKS

- Need more examples.

- Benchmarkable but more realistic HTTP server?

- Example of using UDP.

- Write up a tutorial for the scheduling API.

- More systematic approach to logging.  Logger objects?  What about
  heavy-duty logging, tracking essentially all task state changes?

- Restructure directory, move demos and benchmarks to subdirectories.


TO DO LATER

- Wrap select(), epoll() etc. in try/except checking for EINTR.

- Move accept loop into Listener class?  (Windows is said to work
  better if you make many AcceptEx() calls in parallel.)  OTOH we can
  already accept many incoming connections without suspending.

- When multiple tasks are accessing the same socket, they should
  either get interleaved I/O or an immediate exception; it should not
  compromise the integrity of the scheduler or the app or leave a task
  hanging.

- For epoll you probably want to check/(log?) EPOLLHUP and EPOLLERR errors.

- Add the simplest API possible to run a generator with a timeout.

- Do we need call_every()?  (Easily emulated with a loop and sleep().)

- Ensure multiple tasks can do atomic writes to the same pipe (since
  UNIX guarantees that short writes to pipes are atomic).

- Ensure some easy way of distributing accepted connections across tasks.

- Be wary of thread-local storage.  There should be a standard API to
  get the current Context (which holds current task, event loop, and
  maybe more) and a standard meta-API to change how that standard API
  works (i.e. without monkey-patching).

- See how much of asyncore I've already replaced.

- Do we need _async suffixes to all async APIs?

- Do we need synchronous parallel APIs for all async APIs?

- Add a decorator just for documenting a coroutine.  It should set a
  flag on the function.  It should not interfere with methods,
  staticmethod, classmethod and the like.

- Could BufferedReader reuse the standard io module's readers???

- Support ZeroMQ "sockets" which are user objects.  Though possibly
  this can be supported by getting the underlying fd?  See
  http://mail.python.org/pipermail/python-ideas/2012-October/017532.html
  OTOH see 
  https://github.com/zeromq/pyzmq/blob/master/zmq/eventloop/ioloop.py

- Study goroutines (again).

- Benchmarks: http://nichol.as/benchmark-of-python-web-servers


FROM OLDER LIST

- Is it better to have separate add_{reader,writer} methods, vs. one
  add_thingie method taking a fd and a r/w flag?

- Multiple readers/writers per socket?  (At which level? pollster,
  eventloop, or scheduler?)

- Could poll() usefully be an iterator?

- Do we need to support more epoll and/or kqueue modes/flags/options/etc.?

- Optimize register/unregister calls away if they cancel each other out?

- Should block() use a queue?

- Add explicit wait queue to wait for Task's completion, instead of
  callbacks?

- Global functions vs. Task methods?

- Is the Task design good?

- Make Task more like Future?  (Or less???)

- Implement various lock styles a la threading.py.

- Add write() calls that don't require yield from.

- Add simple non-async APIs, for simple apps?

- Look at pyfdpdlib's ioloop.py:
  http://code.google.com/p/pyftpdlib/source/browse/trunk/pyftpdlib/lib/ioloop.py


MISTAKES I MADE

- Forgetting yield from.  (E.g.: scheduler.sleep(1); listener.accept().)

- Forgot to add bare yield at end of internal function, after block().

- Forgot to call add_done_callback().

- Forgot to pass an undoer to block(), bug only found when cancelled.

- Subtle accounting mistake in a callback.

- Used context.eventloop from a different thread, forgetting about TLS.

- Nasty race: eventloop.ready may contain both an I/O callback and a
  cancel callback.  How to avoid?  Keep the DelayedCall in ready.  Is
  that enough?

- If a toplevel task raises an error it just stops and nothing is logged
  unless you have debug logging on.  This confused me.  (Then again,
  previously I logged whenever a task raised an error, and that was too
  chatty...)

- Forgot to set the connection socket returned by accept() in
  nonblocking mode.

- Nastiest so far (cost me about a day): A race condition in
  call_in_thread() where the Future's done_callback (which was
  task.unblock()) would run immediately at the time when
  add_done_callback() was called, and this screwed over the task
  state.  Solution: wrap the callback in eventloop.call_later().
  Ironically, I had a comment stating there might be a race condition.
